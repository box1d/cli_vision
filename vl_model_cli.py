"""
åŒ…è±†ç”µè„‘ - AI æ™ºèƒ½æ§åˆ¶ç³»ç»Ÿ (å‘½ä»¤è¡Œç‰ˆæœ¬æ ¸å¿ƒæ¨¡å—)
å®Œå…¨ç…§æ¬GUIç‰ˆæœ¬é€»è¾‘
"""

import os
import base64
import cv2
import numpy as np
from openai import OpenAI
import json
import re
import time
import pyautogui
import pyperclip
import signal
from pydantic import BaseModel
import platform

# å…¨å±€é€€å‡ºæ ‡å¿—
should_exit = False

# å…¨å±€å›è°ƒå‡½æ•°ï¼Œç”¨äºé€šçŸ¥ä¸»ç¨‹åºAIè¾“å‡ºçš„åæ ‡
coordinate_callback = None

# å…¨å±€ä¸Šä¸‹æ–‡å†å²è®°å½•ï¼ˆä¿å­˜æœ€è¿‘3æ¬¡ï¼‰
conversation_history = []

current_os = platform.system()

# å‘½ä»¤è¡Œæ—¥å¿—æ‰“å°å‡½æ•°
def log_print(*args, **kwargs):
    """å‘½ä»¤è¡Œæ—¥å¿—æ‰“å°å‡½æ•°"""
    print(*args, **kwargs)

# è®¾ç½®åæ ‡å›è°ƒå‡½æ•°
def set_coordinate_callback(callback):
    global coordinate_callback
    coordinate_callback = callback

# ä¿¡å·å¤„ç†å‡½æ•°
def signal_handler(sig, frame):
    global should_exit
    log_print("\næ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
    should_exit = True

# è®¾ç½®ä¿¡å·å¤„ç†å™¨
signal.signal(signal.SIGINT, signal_handler)

# åŠ è½½é…ç½®æ–‡ä»¶
def load_config(config_path="config.json"):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
        log_print(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
        return config
    except Exception as e:
        log_print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None

# æˆªå›¾å‡½æ•°
def capture_screen_and_save(save_path="imgs/screen.png", optimize_for_speed=True, max_png=1280):
    """æˆªå›¾å¹¶ä¿å­˜"""
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.dirname(save_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    try:
        # æˆªå›¾
        screenshot = pyautogui.screenshot()
        screenshot_np = np.array(screenshot)
        screenshot_bgr = cv2.cvtColor(screenshot_np, cv2.COLOR_RGB2BGR)

        scale = 1
        if optimize_for_speed:
            height, width, _ = screenshot_bgr.shape
            max_edge = max(height, width)
            if max_edge > max_png:
                scale = max_png / max_edge
                screenshot_bgr = cv2.resize(screenshot_bgr, None, fx=scale, fy=scale)
        
        # ä¿å­˜
        save_params = [int(cv2.IMWRITE_PNG_COMPRESSION), 1] if optimize_for_speed else []
        success = cv2.imwrite(save_path, screenshot_bgr, save_params)
        
        return success, scale
    except Exception as e:
        log_print(f"æˆªå›¾å¤±è´¥: {e}")
        return False, 1

# åæ ‡æ ‡è®°å‡½æ•°
def mark_coordinate_on_image(coordinates, input_path=None, output_path=None, point_radius=10, point_color=(0, 0, 255), thickness=-1):
    """åœ¨å›¾ç‰‡ä¸Šæ ‡è®°åæ ‡ç‚¹"""
    if input_path is None:
        input_path = "imgs/screen.png"
    if output_path is None:
        output_path = "imgs/label/screen_label.png"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.dirname(output_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    try:
        # è¯»å–å›¾ç‰‡
        img = cv2.imread(input_path)
        if img is None:
            log_print(f"æ— æ³•è¯»å–å›¾ç‰‡: {input_path}")
            return False
        
        # æ ‡è®°åæ ‡ç‚¹
        if isinstance(coordinates[0], list):
            # å¤šä¸ªåæ ‡ç‚¹
            for coord in coordinates:
                cv2.circle(img, (int(coord[0]), int(coord[1])), point_radius, point_color, thickness)
        else:
            # å•ä¸ªåæ ‡ç‚¹
            cv2.circle(img, (int(coordinates[0]), int(coordinates[1])), point_radius, point_color, thickness)
        
        # ä¿å­˜æ ‡è®°åçš„å›¾ç‰‡
        success = cv2.imwrite(output_path, img)
        if success:
            log_print(f"åæ ‡æ ‡è®°å›¾ç‰‡å·²ä¿å­˜: {output_path}")
        return success
        
    except Exception as e:
        log_print(f"æ ‡è®°åæ ‡å¤±è´¥: {e}")
        return False

# åæ ‡æ˜ å°„ï¼ˆå®Œå…¨ç…§æ¬GUIç‰ˆæœ¬ï¼‰
def map_coordinates(x, y, scale, img_width=None, img_height=None):
    """
    å°†åæ ‡æ˜ å°„åˆ°å®é™…å±å¹•ä¸Š
    å®Œå…¨ç…§æ¬GUIç‰ˆæœ¬çš„é€»è¾‘
    """
    # ç¡®ä¿åæ ‡å€¼åœ¨åˆç†èŒƒå›´å†…
    x = max(-100000, min(100000, x))
    y = max(-100000, min(100000, y))
    
    # å¦‚æœæä¾›äº†å›¾åƒå®½é«˜ï¼Œä½¿ç”¨ç›¸å¯¹åæ ‡åˆ°ç»å¯¹åæ ‡çš„è½¬æ¢å…¬å¼
    if img_width and img_height:
        # å°†ç›¸å¯¹åæ ‡è½¬æ¢ä¸ºç»å¯¹åæ ‡
        x_abs = (x / 1000) * img_width
        y_abs = (y / 1000) * img_height
    else:
        # ä¿æŒåŸæœ‰é€»è¾‘ï¼Œç›´æ¥é™¤ä»¥ç¼©æ”¾æ¯”ä¾‹
        x_abs = x
        y_abs = y
    
    # åº”ç”¨ç¼©æ”¾æ¯”ä¾‹æ˜ å°„åˆ°å®é™…å±å¹•
    x_r = x_abs / scale
    y_r = y_abs / scale
    
    # ç¡®ä¿æœ€ç»ˆåæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
    x_r = max(0, min(100000, x_r))
    y_r = max(0, min(100000, y_r))
    
    return x_r, y_r

# ç§»åŠ¨é¼ æ ‡åˆ°åæ ‡å¹¶æ‰§è¡Œæ“ä½œï¼ˆå®Œå…¨ç…§æ¬GUIç‰ˆæœ¬ï¼‰
def move_mouse_to_coordinates(coordinates, action, type_information="", scale=1, img_width=None, img_height=None, duration=0.1):
    """
    ç§»åŠ¨é¼ æ ‡åˆ°æŒ‡å®šåæ ‡å¹¶æ‰§è¡Œæ“ä½œ
    å®Œå…¨ç…§æ¬GUIç‰ˆæœ¬çš„é€»è¾‘
    """
    # éªŒè¯åæ ‡æœ‰æ•ˆæ€§çš„è¾…åŠ©å‡½æ•°
    def validate_coordinate(coord):
        """ç¡®ä¿åæ ‡å€¼åœ¨åˆç†èŒƒå›´å†…"""
        if isinstance(coord, (int, float)):
            return max(-100000, min(100000, coord))
        return coord
    
    # éªŒè¯å¹¶ä¿®å¤åæ ‡
    def fix_coordinates(coords):
        """ä¿®å¤åæ ‡æ•°æ®ï¼Œç¡®ä¿å…¶æ ¼å¼æ­£ç¡®ä¸”å€¼åœ¨åˆç†èŒƒå›´å†…"""
        if isinstance(coords[0], list):
            # æ‹–æ‹½åæ ‡ [[x1, y1], [x2, y2]]
            return [
                [validate_coordinate(coords[0][0]), validate_coordinate(coords[0][1])],
                [validate_coordinate(coords[1][0]), validate_coordinate(coords[1][1])]
            ]
        else:
            # å•ç‚¹åæ ‡ [x, y]
            return [validate_coordinate(coords[0]), validate_coordinate(coords[1])]
    
    # ä¿®å¤åæ ‡
    coordinates = fix_coordinates(coordinates)
    
    action_str = ""
    
    # å¤„ç†çƒ­é”®æ“ä½œ
    if action == "hotkey":
        if type_information:
            keys = type_information.split()
            current_os = platform.system()
            if current_os == "Darwin":  # macOS
                keys = ["command" if key == "win" or key == "meta" else key for key in keys]
                keys = ["command" if key == "cmd" else key for key in keys]
            else:  # Windowså’Œå…¶ä»–ç³»ç»Ÿ
                keys = ["win" if key == "meta" else key for key in keys]
            
            log_print(f"æ‰§è¡Œçƒ­é”®æ“ä½œ: {'+'.join(keys)}")
            pyautogui.hotkey(*keys)
            action_str = f"æ‰§è¡Œçƒ­é”®æ“ä½œ: {'+'.join(keys)}"+"\n"
        else:
            log_print("çƒ­é”®æ“ä½œä½†æœªæä¾›å¿«æ·é”®ä¿¡æ¯")
        return action_str, None
    
    # å¤„ç†æ‹–æ‹½æ“ä½œ
    if action == "drag" and isinstance(coordinates[0], list):
        start_x, start_y = coordinates[0]
        end_x, end_y = coordinates[1]
        
        # æ˜ å°„åæ ‡
        start_x, start_y = map_coordinates(start_x, start_y, scale, img_width, img_height)
        end_x, end_y = map_coordinates(end_x, end_y, scale, img_width, img_height)
        
        pyautogui.moveTo(start_x, start_y, duration=duration)
        pyautogui.dragTo(end_x, end_y, duration=duration*10)
        log_print(f"å·²å®Œæˆæ‹–æ‹½æ“ä½œ: ({start_x}, {start_y}) -> ({end_x}, {end_y})")
        action_str = action_str + f"å·²å®Œæˆæ‹–æ‹½æ“ä½œ: ({start_x}, {start_y}) -> ({end_x}, {end_y})"+"\n"
        
        mapped_coordinates = [[start_x, start_y], [end_x, end_y]]
    else:
        # å¤„ç†å•ç‚¹æ“ä½œ
        x, y = coordinates
        
        # æ˜ å°„åæ ‡
        x, y = map_coordinates(x, y, scale, img_width, img_height)
        
        # ç§»åŠ¨é¼ æ ‡
        pyautogui.moveTo(x, y, duration=duration)
        log_print(f"ğŸ–±ï¸  ç§»åŠ¨åˆ°åæ ‡: ({x:.0f}, {y:.0f})")
        action_str = f"é¼ æ ‡å·²ç§»åŠ¨åˆ°åæ ‡: ({x}, {y})"+"\n"
        
        # ä¿å­˜æ˜ å°„åçš„åæ ‡
        mapped_coordinates = [x, y]
        
        # æ‰§è¡Œç›¸åº”æ“ä½œ
        if action == "click":
            pyautogui.click()
            log_print(f"ğŸ‘† ç‚¹å‡»å®Œæˆ")
            action_str = action_str + f"å·²ç‚¹å‡» ({x}, {y})"+"\n"
        elif action == "double_click":
            pyautogui.doubleClick()
            log_print(f"å·²åŒå‡» ({x}, {y})")
            action_str = action_str + f"å·²åŒå‡» ({x}, {y})"+"\n" 
        elif action == "long_press":
            pyautogui.mouseDown()
            log_print(f"å·²é•¿æŒ‰ ({x}, {y})")
            action_str = action_str + f"å·²é•¿æŒ‰ ({x}, {y})"+"\n" 
        elif action == "right_click":
            pyautogui.rightClick()
            log_print(f"å·²å³é”®ç‚¹å‡» ({x}, {y})")
            action_str = action_str + f"å·²å³é”®ç‚¹å‡» ({x}, {y})"+"\n" 
        elif action == "scroll_up":
            pyautogui.scroll(500)
            log_print(f"å·²å‘ä¸Šæ»šåŠ¨ ({x}, {y})")
            action_str = action_str + f"å·²å‘ä¸Šæ»šåŠ¨ ({x}, {y})"+"\n" 
        elif action == "scroll_down":
            pyautogui.scroll(-500)
            log_print(f"å·²å‘ä¸‹æ»šåŠ¨ ({x}, {y})")
            action_str = action_str + f"å·²å‘ä¸‹æ»šåŠ¨ ({x}, {y})"+"\n" 
        else:
            log_print(f"æœªçŸ¥æ“ä½œ: {action}")
    
    time.sleep(0.2)
    if type_information != "" and action != "hotkey":
        pyperclip.copy(type_information)
        
        # æ ¹æ®æ“ä½œç³»ç»Ÿæ‰§è¡Œç²˜è´´ï¼ˆç…§æ¬GUIç‰ˆæœ¬é€»è¾‘ï¼‰
        current_os = platform.system()
        time.sleep(0.1)
        if current_os == "Darwin":  # macOS
            # macOSä¸Šä½¿ç”¨æ›´å¯é çš„ç²˜è´´æ–¹æ³•
            time.sleep(0.2)
            pyautogui.keyDown('command')
            time.sleep(0.1)
            pyautogui.press('v')
            time.sleep(0.1)
            pyautogui.keyUp('command')
        else:  # Windowså’Œå…¶ä»–ç³»ç»Ÿ
            pyautogui.hotkey('ctrl', 'v')
        
        log_print(f"âŒ¨ï¸  ç²˜è´´æ–‡æœ¬: {type_information}")
        time.sleep(0.5)
        pyautogui.press('enter')
        action_str = action_str + f"å·²ç²˜è´´æ–‡æœ¬: {type_information}"+"\n"
    
    return action_str, mapped_coordinates

# ç¼–ç å›¾ç‰‡ä¸ºbase64
def encode_image(image_path):
    """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64æ ¼å¼"""
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        log_print(f"å›¾ç‰‡ç¼–ç å¤±è´¥: {e}")
        return None

# AIå“åº”æ¨¡å‹ï¼ˆæ–°æ ¼å¼ï¼‰
class AIResponse(BaseModel):
    status: str = "in_progress"
    description: str = ""
    target: str = ""
    action: dict = {}
    
    # å…¼å®¹æ—§æ ¼å¼å­—æ®µ
    current_status: str = ""
    whether_completed: str = "False"
    element_info: str = ""
    coordinates: list = []
    type_information: str = ""
    
    def __init__(self, **data):
        # å¤„ç†actionå­—æ®µçš„ç±»å‹è½¬æ¢
        if 'action' in data and isinstance(data['action'], str):
            # å¦‚æœactionæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            action_str = data['action']
            data['action'] = {
                "type": action_str,
                "coordinates": data.get('coordinates', []),
                "text": data.get('type_information', '')
            }
        elif 'action' not in data or not data['action']:
            # å¦‚æœæ²¡æœ‰actionå­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼
            data['action'] = {
                "type": "wait",
                "coordinates": [0, 0],
                "text": ""
            }
        
        super().__init__(**data)

def parse_ai_response(response_text):
    """è§£æAIçš„å“åº”æ–‡æœ¬"""
    try:
        # å°è¯•è§£æJSONæ ¼å¼
        if response_text.strip().startswith('```json'):
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                response_data = json.loads(json_str)
            else:
                response_data = {}
        elif response_text.strip().startswith('{'):
            response_data = json.loads(response_text)
        else:
            response_data = {}
        
        # å…¼å®¹ä¸åŒçš„å­—æ®µå
        action = response_data.get('action', 'wait')
        coordinate = response_data.get('coordinate', [])
        coordinates = response_data.get('coordinates', [])
        text = response_data.get('text', '')
        type_information = response_data.get('type_information', '')
        reasoning = response_data.get('reasoning', '')
        whether_completed = response_data.get('whether_completed', 'False')
        current_status = response_data.get('current_status', '')
        element_info = response_data.get('element_info', '')
        
        # å¤„ç†åæ ‡å­—ç¬¦ä¸²æ ¼å¼ï¼ˆå¦‚"[812, 119]"ï¼‰
        if isinstance(coordinates, str):
            try:
                coordinates = json.loads(coordinates)
            except:
                coordinates = []
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œå°è¯•æ–‡æœ¬è§£æ
        if not response_data:
            action_match = re.search(r'action[:\s]*["\']?([^"\'\n,]+)["\']?', response_text, re.IGNORECASE)
            coordinate_match = re.search(r'coordinate[s]?[:\s]*\[([^\]]+)\]', response_text, re.IGNORECASE)
            text_match = re.search(r'text[:\s]*["\']([^"\']+)["\']', response_text, re.IGNORECASE)
            completed_match = re.search(r'whether_completed[:\s]*["\']?([^"\'\n,]+)["\']?', response_text, re.IGNORECASE)
            
            action = action_match.group(1).strip() if action_match else "wait"
            whether_completed = completed_match.group(1).strip() if completed_match else "False"
            
            if coordinate_match:
                coord_str = coordinate_match.group(1)
                coordinates = [float(x.strip()) for x in coord_str.split(',')]
            
            text = text_match.group(1) if text_match else ""
        
        return AIResponse(
            status=response_data.get('status', 'in_progress'),
            description=response_data.get('description', ''),
            target=response_data.get('target', ''),
            action=response_data.get('action', {}),
            current_status=current_status,
            whether_completed=whether_completed,
            element_info=element_info,
            coordinates=coordinates,
            type_information=type_information or text
        )
        
    except Exception as e:
        log_print(f"è§£æAIå“åº”å¤±è´¥: {e}")
        log_print(f"å“åº”å†…å®¹: {response_text}")
        return AIResponse(action="wait", coordinate=[], coordinates=[], text="")

# ä¸»æ§åˆ¶å‡½æ•°
def auto_control_computer(user_content):
    """è‡ªåŠ¨æ§åˆ¶ç”µè„‘çš„ä¸»å‡½æ•°"""
    global should_exit
    
    # åŠ è½½é…ç½®
    config = load_config()
    if not config:
        return "é…ç½®åŠ è½½å¤±è´¥"
    
    # è·å–é…ç½®å‚æ•°
    api_key = config["api_config"]["api_key"]
    base_url = config["api_config"]["base_url"]
    model_name = config["api_config"]["model_name"]
    max_iterations = config["execution_config"]["max_visual_model_iterations"]
    
    if not api_key:
        return "APIå¯†é’¥æœªé…ç½®"
    
    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
    client = OpenAI(api_key=api_key, base_url=base_url)
    
    # è¯»å–ç³»ç»Ÿæç¤ºï¼ˆä½¿ç”¨æ–°ç‰ˆæœ¬promptï¼‰
    system_prompt_file = "get_next_action_AI_doubao_mac_new.txt" if current_os == "Darwin" else "get_next_action_AI_doubao_new.txt"
    
    try:
        # å°è¯•å¤šç§ç¼–ç æ–¹å¼è¯»å–æ–‡ä»¶
        encodings = ['utf-8', 'utf-8-sig', 'gbk', 'latin1']
        system_prompt = None
        
        for encoding in encodings:
            try:
                with open(system_prompt_file, "r", encoding=encoding, errors='ignore') as f:
                    system_prompt = f.read()
                log_print(f"æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è¯»å–ç³»ç»Ÿæç¤ºæ–‡ä»¶")
                break
            except UnicodeDecodeError:
                continue
        
        if system_prompt is None:
            log_print("æ— æ³•è¯»å–ç³»ç»Ÿæç¤ºæ–‡ä»¶")
            return "ç³»ç»Ÿæç¤ºæ–‡ä»¶è¯»å–å¤±è´¥"
        
        # æ¸…ç†å¯èƒ½çš„æ— æ•ˆå­—ç¬¦
        system_prompt = system_prompt.encode('utf-8', errors='ignore').decode('utf-8')
        
    except Exception as e:
        log_print(f"è¯»å–ç³»ç»Ÿæç¤ºæ–‡ä»¶å¤±è´¥: {e}")
        return "ç³»ç»Ÿæç¤ºæ–‡ä»¶è¯»å–å¤±è´¥"
    
    log_print(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {user_content}")
    log_print(f"æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
    
    iteration = 0
    
    while iteration < max_iterations and not should_exit:
        iteration += 1
        log_print(f"\nğŸ”„ === ç¬¬ {iteration} æ¬¡è¿­ä»£ ===")
        
        # æˆªå›¾
        log_print("ğŸ“¸ æ­£åœ¨æˆªå–å±å¹•...")
        success, scale = capture_screen_and_save(
            save_path=config["screenshot_config"]["input_path"],
            optimize_for_speed=config["screenshot_config"]["optimize_for_speed"],
            max_png=config["screenshot_config"]["max_png"]
        )
        
        if not success:
            log_print("âŒ æˆªå›¾å¤±è´¥")
            continue
        
        # è·å–å›¾ç‰‡å°ºå¯¸ç”¨äºåæ ‡æ˜ å°„
        screenshot_path = config["screenshot_config"]["input_path"]
        img = cv2.imread(screenshot_path)
        if img is not None:
            img_height, img_width = img.shape[:2]
        else:
            img_width = img_height = None
        
        # ç¼–ç å›¾ç‰‡
        base64_image = encode_image(screenshot_path)
        
        if not base64_image:
            log_print("âŒ å›¾ç‰‡ç¼–ç å¤±è´¥")
            continue
        
        log_print("ğŸ” æ­£åœ¨è°ƒç”¨AIæ¨¡å‹åˆ†æ...")
        
        # æ¸…ç†ç”¨æˆ·è¾“å…¥ä¸­çš„æ— æ•ˆå­—ç¬¦
        clean_user_content = user_content.encode('utf-8', errors='ignore').decode('utf-8')
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«æœ€è¿‘3æ¬¡çš„ä¸Šä¸‹æ–‡
        messages = [{"role": "system", "content": system_prompt}]
        
        # æ·»åŠ å†å²ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘3æ¬¡ï¼‰
        for history_item in conversation_history[-3:]:
            messages.append(history_item["user_message"])
            messages.append(history_item["assistant_message"])
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        current_user_message = {
            "role": "user",
            "content": [
                {"type": "text", "text": clean_user_content},
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                }
            ]
        }
        messages.append(current_user_message)
        
        try:
            response = client.chat.completions.create(
                model=model_name,
                messages=messages,
                max_tokens=1000,
                temperature=0.1
            )
            
            ai_response_text = response.choices[0].message.content
            # æ¸…ç†AIå“åº”ä¸­çš„æ— æ•ˆå­—ç¬¦
            ai_response_text = ai_response_text.encode('utf-8', errors='ignore').decode('utf-8')
            log_print(f"ğŸ¤– AIåŸå§‹å“åº”:\n{ai_response_text}")
            
            # ä¿å­˜åˆ°å†å²è®°å½•
            history_item = {
                "user_message": current_user_message,
                "assistant_message": {"role": "assistant", "content": ai_response_text}
            }
            conversation_history.append(history_item)
            
            # åªä¿ç•™æœ€è¿‘3æ¬¡è®°å½•
            if len(conversation_history) > 3:
                conversation_history.pop(0)
            
            # è§£æå¹¶æ‰§è¡Œæ“ä½œ
            ai_response = parse_ai_response(ai_response_text)
            
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆï¼ˆæ–°æ ¼å¼ï¼‰
            if ai_response.status in ['completed', 'failed']:
                if ai_response.status == 'completed':
                    log_print("âœ… ä»»åŠ¡å®Œæˆ!")
                    return "ä»»åŠ¡å®Œæˆ"
                else:
                    log_print("âš ï¸  ä»»åŠ¡å¤±è´¥æˆ–è¿‡äºå¤æ‚")
                    return "ä»»åŠ¡å¤±è´¥æˆ–è¿‡äºå¤æ‚"
            
            # æ˜¾ç¤ºAIåˆ†æç»“æœ
            log_print(f"ğŸ¯ AIåˆ†æ: {ai_response.description}")
            log_print(f"ğŸ”§ æ‰§è¡Œæ“ä½œ: {ai_response.action.get('type', 'unknown')}")
            if ai_response.action.get('coordinates'):
                log_print(f"ğŸ“ ç›®æ ‡åæ ‡: {ai_response.action['coordinates']}")
            
            # æ‰§è¡Œæ“ä½œï¼ˆä½¿ç”¨æ–°æ ¼å¼ï¼‰
            action_type = ai_response.action.get('type', 'wait')
            coordinates = ai_response.action.get('coordinates', [])
            text = ai_response.action.get('text', '')
            
            if coordinates and len(coordinates) >= 2 and action_type != 'wait':
                action_str, mapped_coordinates = move_mouse_to_coordinates(
                    coordinates, action_type, text, 
                    scale=scale, img_width=img_width, img_height=img_height
                )
                
                # æ ‡è®°åæ ‡ç‚¹ï¼ˆç…§æ¬GUIç‰ˆæœ¬é€»è¾‘ï¼‰
                if mapped_coordinates:
                    if isinstance(mapped_coordinates[0], list):
                        # æ‹–æ‹½åæ ‡ [[x1, y1], [x2, y2]]
                        image_coordinates = []
                        for coord in mapped_coordinates:
                            img_x = int(coord[0] * scale)
                            img_y = int(coord[1] * scale)
                            image_coordinates.append([img_x, img_y])
                    else:
                        # å•ç‚¹åæ ‡ [x, y]
                        img_x = int(mapped_coordinates[0] * scale)
                        img_y = int(mapped_coordinates[1] * scale)
                        image_coordinates = [img_x, img_y]
                    
                    # ç”Ÿæˆæ ‡è®°å›¾ç‰‡
                    output_filename = f"screen_label{iteration}.png"
                    output_path = os.path.join("imgs/label", output_filename)
                    mark_coordinate_on_image(image_coordinates, screenshot_path, output_path)
                
                # é€šçŸ¥åæ ‡å›è°ƒ
                if coordinate_callback and mapped_coordinates:
                    if isinstance(mapped_coordinates[0], list):
                        coordinate_callback(mapped_coordinates[0][0], mapped_coordinates[0][1])
                    else:
                        coordinate_callback(mapped_coordinates[0], mapped_coordinates[1])
            else:
                log_print("âš ï¸  æœªæä¾›æœ‰æ•ˆåæ ‡æˆ–æ“ä½œ")
                time.sleep(1)
            
        except Exception as e:
            log_print(f"âŒ AIè°ƒç”¨å¤±è´¥: {e}")
            time.sleep(2)
    
    if should_exit:
        log_print("ğŸ›‘ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        return "ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ"
    else:
        log_print(f"â° è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({max_iterations})")
        return f"è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({max_iterations})"
